{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yazanjian/students-performance-notebook?scriptVersionId=144872159\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Students Performance Study\nIn this notebook, we are going to study the performance of some students based on the folllowing [dataset](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams) \n\nThe notebook is divided into sections as follows: \n1. Dataset Import: Load and read the dataset\n2. Some Analysis: Study the dataset and the relations between the features. \n3. Data Preprocessing: Transform the problem into classification problem by averaging the three exam results and replace the average with a binary category; Pass >= 65 and No Pass < 65. Then do categorical encoding. \n4. Model Training and Evaluation: Using some ML models available in sklearn library \n\n\n**Note**: This notebook uses a utility file developed by the same author, and available [here](https://www.kaggle.com/code/yazanjian/utils) on kaggle","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport utils\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.preprocessing import OrdinalEncoder\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T14:31:03.833781Z","iopub.execute_input":"2023-10-01T14:31:03.834103Z","iopub.status.idle":"2023-10-01T14:31:06.077864Z","shell.execute_reply.started":"2023-10-01T14:31:03.834078Z","shell.execute_reply":"2023-10-01T14:31:06.077079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Import","metadata":{}},{"cell_type":"code","source":"# Read the dataframe\ndf = pd.read_csv('/kaggle/input/students-performance-in-exams/StudentsPerformance.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:06.079492Z","iopub.execute_input":"2023-10-01T14:31:06.080328Z","iopub.status.idle":"2023-10-01T14:31:06.120335Z","shell.execute_reply.started":"2023-10-01T14:31:06.080299Z","shell.execute_reply":"2023-10-01T14:31:06.119163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some Analysis\nIn this section we are goining to check the following: \n1. The number of null values for each column\n2. Visualize the frequency of each value per feature\n3. Analyze any possible relation between ","metadata":{}},{"cell_type":"code","source":"# Print some details of the loaded df\nprint(\"The total number of records is: {} with {} features \\n\".format(df.shape[0], df.shape[1]))\nprint(\"Data description \\n {} \\n\".format(df.describe()))\nprint(\"{} \\n\".format(df.info()))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:06.121422Z","iopub.execute_input":"2023-10-01T14:31:06.121651Z","iopub.status.idle":"2023-10-01T14:31:06.16388Z","shell.execute_reply.started":"2023-10-01T14:31:06.121631Z","shell.execute_reply":"2023-10-01T14:31:06.163192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize features\nutils.visualize_features(df)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:06.167101Z","iopub.execute_input":"2023-10-01T14:31:06.167492Z","iopub.status.idle":"2023-10-01T14:31:07.926796Z","shell.execute_reply.started":"2023-10-01T14:31:06.167466Z","shell.execute_reply":"2023-10-01T14:31:07.926266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the correlation matrix between the three exams scores\ncorrelation_columns = ['math score', 'reading score', 'writing score']\nutils.plot_correlation_figure(df, correlation_columns)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:07.927504Z","iopub.execute_input":"2023-10-01T14:31:07.927734Z","iopub.status.idle":"2023-10-01T14:31:08.180998Z","shell.execute_reply.started":"2023-10-01T14:31:07.927713Z","shell.execute_reply":"2023-10-01T14:31:08.178356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a scatter plot\nsns.scatterplot(x=df['reading score'], y=df['writing score'])\n\n# Add labels and title\nplt.xlabel('reading score')\nplt.ylabel('writing score')\nplt.title('Scatter Plot Example')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.182163Z","iopub.execute_input":"2023-10-01T14:31:08.182507Z","iopub.status.idle":"2023-10-01T14:31:08.414691Z","shell.execute_reply.started":"2023-10-01T14:31:08.182482Z","shell.execute_reply":"2023-10-01T14:31:08.413597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Analysis Discussion:\n* As we can notice from the previous cells, we have **1000 records**, with **no missing data**. \n* We have **5 categorical features** with **3 numerical attributes** (exam results). \n* Test preparation course and lunch features have imbalanced data. \n* Overall, there is a correlation between the three exams. Moroever, **there is a clear relationship between the writing exam score and reading exam score**. ","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing \n\nIn this section, we are going to do the following:\n1. Convert the problem in hand into classification problem. The process for that is to calculate the avg. for all the three exams. After that, **all avg. results >= 65** will be **labled as True** and **all results < 65** will be **labled as False**. \n2. Extract the target and features dfs.\n3. Categorical Encoding.","metadata":{}},{"cell_type":"markdown","source":"##### 1. Convert the problem into classification","metadata":{}},{"cell_type":"code","source":"df['Passed'] = df[['math score', 'reading score', 'writing score']].mean(axis=1) >= 65\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.416354Z","iopub.execute_input":"2023-10-01T14:31:08.416594Z","iopub.status.idle":"2023-10-01T14:31:08.434216Z","shell.execute_reply.started":"2023-10-01T14:31:08.416575Z","shell.execute_reply":"2023-10-01T14:31:08.433377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the exam results and keep the Passed column\ndf.drop(columns=['math score', 'reading score', 'writing score'], inplace=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.435369Z","iopub.execute_input":"2023-10-01T14:31:08.436032Z","iopub.status.idle":"2023-10-01T14:31:08.451823Z","shell.execute_reply.started":"2023-10-01T14:31:08.436003Z","shell.execute_reply":"2023-10-01T14:31:08.451117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['Passed']].describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.452879Z","iopub.execute_input":"2023-10-01T14:31:08.453187Z","iopub.status.idle":"2023-10-01T14:31:08.462777Z","shell.execute_reply.started":"2023-10-01T14:31:08.453168Z","shell.execute_reply":"2023-10-01T14:31:08.461944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.visualize_single_feature_as_histogram(df, 'Passed')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.465398Z","iopub.execute_input":"2023-10-01T14:31:08.465625Z","iopub.status.idle":"2023-10-01T14:31:08.842676Z","shell.execute_reply.started":"2023-10-01T14:31:08.465607Z","shell.execute_reply":"2023-10-01T14:31:08.841242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 2. Extract the features and target dataframes","metadata":{}},{"cell_type":"code","source":"# Extract the target attribute and the features dataframe\ntarget = df['Passed']\nfeatures = df.drop(columns=['Passed'])\nfeatures","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.845049Z","iopub.execute_input":"2023-10-01T14:31:08.846101Z","iopub.status.idle":"2023-10-01T14:31:08.85683Z","shell.execute_reply.started":"2023-10-01T14:31:08.846035Z","shell.execute_reply":"2023-10-01T14:31:08.856261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 3. Categorical Encoding","metadata":{}},{"cell_type":"code","source":"features_encoded = pd.get_dummies(features)\nfeatures_encoded","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.857922Z","iopub.execute_input":"2023-10-01T14:31:08.858298Z","iopub.status.idle":"2023-10-01T14:31:08.887365Z","shell.execute_reply.started":"2023-10-01T14:31:08.858275Z","shell.execute_reply":"2023-10-01T14:31:08.886189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training\nIn this section, we are going to train some sklearn classification models, namely LR, RF, KNN and DT. \nSteps: \n1. Split the data into train and test splits with 80% and 20% respectively. \n2. Model training & Model evaluation","metadata":{}},{"cell_type":"markdown","source":"##### 1. Split the data into train and test splits with 80% and 20% respectively.\n","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(features_encoded, target, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.888711Z","iopub.execute_input":"2023-10-01T14:31:08.889078Z","iopub.status.idle":"2023-10-01T14:31:08.896647Z","shell.execute_reply.started":"2023-10-01T14:31:08.889047Z","shell.execute_reply":"2023-10-01T14:31:08.895179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shape of the dfs\nprint(\"Shape of X_train {}\".format(X_train.shape))\nprint('Shape of X_test {}'.format(X_test.shape))\nprint('Shape of y_train {}'.format(y_train.shape))\nprint('Shape of y_test {}'.format(y_test.shape))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.898092Z","iopub.execute_input":"2023-10-01T14:31:08.898468Z","iopub.status.idle":"2023-10-01T14:31:08.907312Z","shell.execute_reply.started":"2023-10-01T14:31:08.898448Z","shell.execute_reply":"2023-10-01T14:31:08.906279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### 2. Model training & Evaluation\n","metadata":{}},{"cell_type":"markdown","source":"**Logistic Regression**","metadata":{}},{"cell_type":"code","source":"#Create and fit the model on training data\nLR_model = LogisticRegression(solver='liblinear', penalty='l2', random_state=32).fit(X_train, y_train)\n\nprint(\"The accuracy score for the training data = {}\".format(LR_model.score(X_train, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(LR_model.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.9091Z","iopub.execute_input":"2023-10-01T14:31:08.90948Z","iopub.status.idle":"2023-10-01T14:31:08.934167Z","shell.execute_reply.started":"2023-10-01T14:31:08.909454Z","shell.execute_reply":"2023-10-01T14:31:08.933517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Support Vector Machine**\n","metadata":{}},{"cell_type":"code","source":"SVC_model = SVC(kernel='poly', degree=4, random_state=42).fit(X_train, y_train)\nprint(\"The accuracy score for the training data = {}\".format(SVC_model.score(X_train, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(SVC_model.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.935067Z","iopub.execute_input":"2023-10-01T14:31:08.935669Z","iopub.status.idle":"2023-10-01T14:31:08.997806Z","shell.execute_reply.started":"2023-10-01T14:31:08.935644Z","shell.execute_reply":"2023-10-01T14:31:08.996216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVC_model = SVC(kernel='rbf', C=0.5, gamma='scale', random_state=42).fit(X_train, y_train)\nprint(\"The accuracy score for the training data = {}\".format(SVC_model.score(X_train, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(SVC_model.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:08.998846Z","iopub.execute_input":"2023-10-01T14:31:08.999116Z","iopub.status.idle":"2023-10-01T14:31:09.074422Z","shell.execute_reply.started":"2023-10-01T14:31:08.999094Z","shell.execute_reply":"2023-10-01T14:31:09.073288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Decision Tree**\n","metadata":{}},{"cell_type":"code","source":"DT_model = DecisionTreeClassifier(random_state=42).fit(X_train, y_train)\nprint(\"The accuracy score for the training data = {}\".format(DT_model.score(X_train, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(DT_model.score(X_test, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.075947Z","iopub.execute_input":"2023-10-01T14:31:09.076333Z","iopub.status.idle":"2023-10-01T14:31:09.093674Z","shell.execute_reply.started":"2023-10-01T14:31:09.076294Z","shell.execute_reply":"2023-10-01T14:31:09.092677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Apply PCA before training","metadata":{}},{"cell_type":"code","source":"principal=PCA(n_components=5)\nX_train_pca = principal.fit_transform(X_train)\nX_test_pca = principal.transform(X_test)\nX_train_pca.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.094699Z","iopub.execute_input":"2023-10-01T14:31:09.095555Z","iopub.status.idle":"2023-10-01T14:31:09.124385Z","shell.execute_reply.started":"2023-10-01T14:31:09.095527Z","shell.execute_reply":"2023-10-01T14:31:09.12338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LR with PCA**","metadata":{}},{"cell_type":"code","source":"#Create and fit the model on training data\nLR_model_pca = LogisticRegression(solver='liblinear', penalty='l2', random_state=32).fit(X_train_pca, y_train)\n\nprint(\"The accuracy score for the training data = {}\".format(LR_model_pca.score(X_train_pca, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(LR_model_pca.score(X_test_pca, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.125571Z","iopub.execute_input":"2023-10-01T14:31:09.125852Z","iopub.status.idle":"2023-10-01T14:31:09.137842Z","shell.execute_reply.started":"2023-10-01T14:31:09.125827Z","shell.execute_reply":"2023-10-01T14:31:09.136585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Support Vector Machine with PCA**\n","metadata":{}},{"cell_type":"code","source":"SVC_model_pca = SVC(kernel='rbf', C=0.5, gamma='scale', random_state=42).fit(X_train_pca, y_train)\nprint(\"The accuracy score for the training data = {}\".format(SVC_model_pca.score(X_train_pca, y_train)))\nprint(\"The accuracy score for the testing data = {}\".format(SVC_model_pca.score(X_test_pca, y_test)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.139001Z","iopub.execute_input":"2023-10-01T14:31:09.139349Z","iopub.status.idle":"2023-10-01T14:31:09.206425Z","shell.execute_reply.started":"2023-10-01T14:31:09.13932Z","shell.execute_reply":"2023-10-01T14:31:09.205619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Ordinal Encoding with PCA","metadata":{}},{"cell_type":"markdown","source":"1. Apply Ordinal Encoding","metadata":{}},{"cell_type":"code","source":"# Split the data into training and testing sets (80% train, 20% test)\nX_train_oe, X_test_oe, y_train_oe, y_test_oe = train_test_split(features, target, test_size=0.3, random_state=42)\n\nenc = OrdinalEncoder()\nX_train_oe = enc.fit_transform(X_train_oe)\nX_test_oe = enc.transform(X_test_oe)\nX_train_oe.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.207543Z","iopub.execute_input":"2023-10-01T14:31:09.207963Z","iopub.status.idle":"2023-10-01T14:31:09.220597Z","shell.execute_reply.started":"2023-10-01T14:31:09.207935Z","shell.execute_reply":"2023-10-01T14:31:09.21991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"principal_oe=PCA(n_components=5)\nX_train_oe_pca = principal_oe.fit_transform(X_train_oe)\nX_test_oe_pca = principal_oe.transform(X_test_oe)\nX_train_oe_pca.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.221857Z","iopub.execute_input":"2023-10-01T14:31:09.222407Z","iopub.status.idle":"2023-10-01T14:31:09.22878Z","shell.execute_reply.started":"2023-10-01T14:31:09.22238Z","shell.execute_reply":"2023-10-01T14:31:09.228157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create and fit the model on training data\nLR_model_oe_pca = LogisticRegression(solver='liblinear', penalty='l1', random_state=32).fit(X_train_oe_pca, y_train_oe)\n\nprint(\"The accuracy score for the training data = {}\".format(LR_model_oe_pca.score(X_train_oe_pca, y_train_oe)))\nprint(\"The accuracy score for the testing data = {}\".format(LR_model_oe_pca.score(X_test_oe_pca, y_test_oe)))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:31:09.229831Z","iopub.execute_input":"2023-10-01T14:31:09.230276Z","iopub.status.idle":"2023-10-01T14:31:09.243583Z","shell.execute_reply.started":"2023-10-01T14:31:09.230252Z","shell.execute_reply":"2023-10-01T14:31:09.242759Z"},"trusted":true},"execution_count":null,"outputs":[]}]}